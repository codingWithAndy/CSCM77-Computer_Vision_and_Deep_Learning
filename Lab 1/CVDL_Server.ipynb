{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision and Deep Learning \n",
    "## Lab 1 - Kinect \n",
    "\n",
    "The following notebook provides functionality which allows the `CVDL_Student.ipynb` notebook to obtain frames from the KinectV2 over TCP/IP.\n",
    "\n",
    "Check the IP address of the machine this script is run on and update `server_ip` in the section on [opening a socket](#open_socket), also update the corresponding address in `CVDL_Student.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports <a id=\"imports\"></a>\n",
    "The following section defines the imports used for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pykinect2 for KinectV2 usage:\n",
    "from pykinect2 import PyKinectV2, PyKinectRuntime\n",
    "\n",
    "# For ndarray handling:\n",
    "import numpy as np\n",
    "\n",
    "# For plots:\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# For image resizing:\n",
    "import skimage\n",
    "\n",
    "# For some timing delays:\n",
    "import time  \n",
    "\n",
    "# For TCP/IP functionality:\n",
    "import socket\n",
    "from struct import pack\n",
    "import _thread as thread\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a KinectV2 object with PyKinect2 <a id=\"PyKinect2\"></a>\n",
    "The following section instantiates a PyKinectRuntime object, which is communicating with the KinectV2 sensor. This PyKinectRuntime object can then use the functionality defined within the pykinect2 module to obtain a wide range of data captured via the kinect; including image, depth, audio, human skeletal tracking, hand gestures and infrared. For this lab we obtain the color, depth, body and infrared data by instantiating our PyKinectRuntime object with the frame sources for the respective streams (`PyKinectV2.FrameSourceTypes_Color`, for example, captures the color image data).\n",
    "\n",
    "We use a little `time.sleep` call here to give the sensor a moment to boot up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a KinectV2 and stream the color, depth, and body information\n",
    "kinect = PyKinectRuntime.PyKinectRuntime(PyKinectV2.FrameSourceTypes_Color |\n",
    "                                         PyKinectV2.FrameSourceTypes_Depth |\n",
    "                                         PyKinectV2.FrameSourceTypes_Body |\n",
    "                                         PyKinectV2.FrameSourceTypes_Infrared)\n",
    "# wait for kinect to startup\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get data from KinectV2 <a id=\"get_kinect_frames\"></a>\n",
    "The following section defines the `get_kinect_frames` function which is called in order to retrieve image, depth, body and infrared data from the KinectV2 using the PyKinect2 package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kinect_frames():\n",
    "    # Subsample the height and width to send over tcpip\n",
    "    new_height = kinect.color_frame_desc.Height // 2\n",
    "    new_width = kinect.color_frame_desc.Width // 2\n",
    "    \n",
    "    \n",
    "    color_frame = np.zeros((new_height, new_width, 4), dtype=np.uint8)\n",
    "    depth_frame = np.zeros((new_height, new_width), dtype=np.uint16)\n",
    "    infrared_frame = np.zeros((new_height, new_width), dtype=np.uint8)\n",
    "    body_frame = []\n",
    "        \n",
    "    # Get BGRA frames\n",
    "    if kinect.has_new_color_frame():\n",
    "        color_frame = kinect.get_last_color_frame()\n",
    "    \n",
    "    # Get depth frames\n",
    "    if kinect.has_new_depth_frame():\n",
    "        depth_frame = kinect.get_last_depth_frame()\n",
    "     \n",
    "    # Get infrared frames\n",
    "    if kinect.has_new_infrared_frame():\n",
    "        infrared_frame = kinect.get_last_infrared_frame()   \n",
    "       \n",
    "     # Get bodies\n",
    "    if kinect.has_new_body_frame():\n",
    "        body_frame = kinect.get_last_body_frame()\n",
    "        \n",
    "    # Resize the frames\n",
    "    color_frame = np.reshape(color_frame, (kinect.color_frame_desc.Height, kinect.color_frame_desc.Width, 4))\n",
    "    color_frame = skimage.transform.resize(color_frame, (new_height, new_width), preserve_range=True)\n",
    "    color_frame = color_frame.flatten().astype(np.uint8)\n",
    "\n",
    "    depth_frame = np.reshape(depth_frame, (kinect.depth_frame_desc.Height, kinect.depth_frame_desc.Width, 1))\n",
    "    depth_frame = skimage.transform.resize(depth_frame, (new_height, new_width), preserve_range=True)\n",
    "    depth_frame = depth_frame.flatten().astype(np.uint16)\n",
    "\n",
    "    infrared_frame = np.reshape(infrared_frame, (kinect.infrared_frame_desc.Height, kinect.infrared_frame_desc.Width, 1))\n",
    "    infrared_frame = skimage.transform.resize(infrared_frame, (new_height, new_width), preserve_range=True)\n",
    "    infrared_frame = np.uint8(infrared_frame.clip(1, 4000) / 16.)\n",
    "        \n",
    "    return depth_frame, color_frame, body_frame, infrared_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to send frames on client connection <a id=\"on_new_client\"></a>\n",
    "The following section defines the `on_new_client` function which is called whenever a new connection is made to the server. This method recieves the number of frames requested and captures that many frames by calling `get_kinect_frames`, it then transfers these back over the TCP/IP connection and then finally closes the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_new_client(conn, addr):\n",
    "    # Loop over requested number of frames and grab color, depth and body\n",
    "    try:\n",
    "        while 1:\n",
    "            # Determine if frames need to be grabbed, or if connection can be closed\n",
    "            receipt = conn.recv(1)\n",
    "            if not receipt: \n",
    "                break\n",
    "            else:\n",
    "                n_frames = int.from_bytes(receipt, byteorder = 'little')\n",
    "                print('Grabbing {0} frames'.format(n_frames))\n",
    "\n",
    "            # Grab new frames\n",
    "            depth_stack = []\n",
    "            color_stack = []\n",
    "            body_stack = []\n",
    "            infra_stack = []\n",
    "            for i_frame in range(n_frames):\n",
    "                print('Grabbed frame ', i_frame)\n",
    "                depth, color, body, infra = get_kinect_frames()\n",
    "                depth_stack.append(depth)\n",
    "                color_stack.append(color)\n",
    "                body_stack.append(body)\n",
    "                infra_stack.append(infra)\n",
    "                #time.sleep(1/10) # wait a bit to grab the next frame\n",
    "\n",
    "            # Send those frames out\n",
    "            for i_frame in range(n_frames):\n",
    "                print('Sending rgb frame ', i_frame)\n",
    "                conn.sendall(pack('>Q', color_stack[i_frame].size))\n",
    "                conn.sendall(color_stack[i_frame])\n",
    "                receipt = conn.recv(1)\n",
    "\n",
    "                print('Sending depth frame ', i_frame)\n",
    "                conn.sendall(pack('>Q', depth_stack[i_frame].size * 2))\n",
    "                conn.sendall(depth_stack[i_frame])\n",
    "                receipt = conn.recv(1)\n",
    "\n",
    "                print('Sending infra frame ', i_frame)\n",
    "                conn.sendall(pack('>Q', infra_stack[i_frame].size))\n",
    "                conn.sendall(infra_stack[i_frame])\n",
    "                receipt = conn.recv(1)\n",
    "    finally:\n",
    "        # Make sure to close the connection on the way out\n",
    "        print('Disconnecting {0}'.format(addr))\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open socket to allow connections and monitor for new requests <a id=\"open_socket\"></a>\n",
    "\n",
    "The following section creates a new socket connection which allows incoming connections from `CVDL_Student`. When a new connection is made it kicks off a thread to `on_new_client` to allow for frames to be captured and sent to the recieving machine over TCP/IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My address is: 137.44.2.186 and my port is: 20156 \n",
      "Connected by  ('137.44.6.85', 53289)\n",
      "Grabbing 10 frames\n",
      "Grabbed frame  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\medwa\\desktop\\pythonwork\\pythonenv\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "c:\\users\\medwa\\desktop\\pythonwork\\pythonenv\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbed frame  1\n",
      "Grabbed frame  2\n",
      "Grabbed frame  3\n",
      "Grabbed frame  4\n",
      "Grabbed frame  5\n",
      "Grabbed frame  6\n",
      "Grabbed frame  7\n",
      "Grabbed frame  8\n",
      "Grabbed frame  9\n",
      "Sending rgb frame  0\n",
      "Sending depth frame  0\n",
      "Sending infra frame  0\n",
      "Sending rgb frame  1\n",
      "Sending depth frame  1\n",
      "Sending infra frame  1\n",
      "Sending rgb frame  2\n",
      "Sending depth frame  2\n",
      "Sending infra frame  2\n",
      "Sending rgb frame  3\n",
      "Sending depth frame  3\n",
      "Sending infra frame  3\n",
      "Sending rgb frame  4\n",
      "Sending depth frame  4\n",
      "Sending infra frame  4\n",
      "Sending rgb frame  5\n",
      "Sending depth frame  5\n",
      "Sending infra frame  5\n",
      "Sending rgb frame  6\n",
      "Sending depth frame  6\n",
      "Sending infra frame  6\n",
      "Sending rgb frame  7\n",
      "Sending depth frame  7\n",
      "Sending infra frame  7\n",
      "Sending rgb frame  8\n",
      "Sending depth frame  8\n",
      "Sending infra frame  8\n",
      "Sending rgb frame  9\n",
      "Sending depth frame  9\n",
      "Sending infra frame  9\n",
      "Disconnecting ('137.44.6.85', 53289)\n"
     ]
    }
   ],
   "source": [
    "# Open up a socket on the current machine for access\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "server_ip = '137.44.2.186' # Edit this to reflect the correct IP address\n",
    "server_port = 20156\n",
    "print('My address is: {0} and my port is: {1} '.format(server_ip, server_port))\n",
    "server_address = (server_ip, 20156)\n",
    "sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "sock.bind(server_address)\n",
    "\n",
    "# Keep server open listening for new connections from client code\n",
    "while 1:\n",
    "    sock.listen(20)\n",
    "    conn, addr = sock.accept()\n",
    "    print('Connected by ', addr)\n",
    "    thread.start_new_thread(on_new_client, (conn, addr))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\medwa\\\\Dropbox\\\\CVDL_Python\\\\Lab_one'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
