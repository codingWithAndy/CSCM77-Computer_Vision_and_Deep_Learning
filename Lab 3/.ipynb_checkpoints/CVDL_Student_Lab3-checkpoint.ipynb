{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Vision and Deep Learning \n",
    "## Lab 3 - Feature Descriptors\n",
    "This lab looks into common feature extractors in the vision community. We will look at various filters on static images, and the use of cascade detectors in detection within video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports <a id=\"imports\"></a>\n",
    "The following section defines the imports used for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ndarray handling:\n",
    "import numpy as np\n",
    "\n",
    "# For plotting:\n",
    "#%matplotlib notebook\n",
    "%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.rcParams['figure.figsize'] = [11,11]\n",
    "\n",
    "# For image processing applications\n",
    "import cv2\n",
    "import skimage.io\n",
    "import skimage.feature\n",
    "import scipy.signal\n",
    "\n",
    "# For saving images\n",
    "import skimage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get vase.jpg image\n",
    "We will use a basic image to look at the various filtering operations, but feel free to substitute in your own. Try more complex image structures, do they all work well on noisy images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = skimage.io.imread('vase.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b15311629d24247afb9ae553e4654d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328, 328, 3)\n",
      "(324, 324)\n"
     ]
    }
   ],
   "source": [
    "# Define the kernel ourselves\n",
    "LoG_filter = np.asarray([[0,  0,   1,  0,  0],\n",
    "                         [0,  1,   2,  1,  0],\n",
    "                         [1,  2, -16,  2,  1],\n",
    "                         [0,  1,   2,  1,  0],\n",
    "                         [0,  0,   1,  0,  0]])\n",
    "\n",
    "# Do the convolution\n",
    "convolution_result = scipy.signal.convolve2d(skimage.color.rgb2gray(image), LoG_filter, mode='valid')\n",
    "\n",
    "# Plot the resulting output\n",
    "plt.figure()\n",
    "plt.imshow(convolution_result)\n",
    "plt.show()\n",
    "\n",
    "# This is interesting. Why?\n",
    "print(image.shape)\n",
    "print(convolution_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prewitt Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c2342e98be41aab5fd887185b7a519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter the image with a Prewitt filter\n",
    "image_prewitt = skimage.filters.prewitt(skimage.color.rgb2gray(image))\n",
    "\n",
    "# Plot the original, the filtered image, and the thresholded result\n",
    "plt.figure()\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(image_prewitt, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(image_prewitt <= skimage.filters.threshold_otsu(image_prewitt), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobel Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c6e939c6ad4d56b8a459bc4d71cd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter the image with a Sobel filter\n",
    "image_sobel = skimage.filters.sobel(skimage.color.rgb2gray(image))\n",
    "\n",
    "# Plot the original, the filtered image, and the thresholded result\n",
    "plt.figure()\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(image_sobel, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(image_sobel <= skimage.filters.threshold_otsu(image_sobel), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764c1b2fc76c4096bc889fe3864fce11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try the horizontal and vertical Sobel's seperately\n",
    "image_sobel = skimage.filters.sobel(skimage.color.rgb2gray(image))\n",
    "image_sobel_h = skimage.filters.sobel_h(skimage.color.rgb2gray(image))\n",
    "image_sobel_v = skimage.filters.sobel_v(skimage.color.rgb2gray(image))\n",
    "\n",
    "# Plot the original, the filtered image, and the thresholded result\n",
    "plt.figure()\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(image_sobel <= skimage.filters.threshold_otsu(image_sobel), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(image_sobel_h >= skimage.filters.threshold_otsu(image_sobel_h), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(image_sobel_v <= skimage.filters.threshold_otsu(image_sobel_v), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ebda60e7dc405c9a9841d8d1cecd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter the image with a Laplace filter\n",
    "image_laplace = skimage.filters.laplace(skimage.color.rgb2gray(image))\n",
    "\n",
    "# Plot the original, the filtered image, and the thresholded result\n",
    "plt.figure()\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(image_laplace, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(image_laplace <= skimage.filters.threshold_otsu(image_laplace), cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haar Cascades\n",
    "The following looks at Haar features and their use in tracking of human faces by use of a cascade classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video in\n",
    "cap = cv2.VideoCapture('face.mp4')\n",
    "\n",
    "# Create Haar cascade detector\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "# Loop over frames in the video and apply cascade detector\n",
    "for i_frame in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "    \n",
    "    # Get frame and convert to grayscale\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "       \n",
    "    # Detect faces and annotate the frame with a bounding box\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        img = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        # Detect eyes in the face and annotate with bounding boxes\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    \n",
    "    # Render the frame\n",
    "    cv2.imshow('img',frame)\n",
    "    cv2.waitKey(2)\n",
    "\n",
    "# Close everything once finished\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HoG Features\n",
    "The utilises the Histogram of Gradients feature extractor on the given image. We can then look at varying the hyperparameters to observe the impact on retained details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8947d43cca4ca8833f62944b5b9de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 327.5, 327.5, -0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract HoG features and obtain both the vector and the HoG visualization image\n",
    "hog, hogvis = skimage.feature.hog(image, visualize=True)\n",
    "\n",
    "# Plot the original and the HoG rose plots\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(hogvis, cmap=plt.cm.gray)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Selected block normalization method is invalid.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-4ba89172503c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhogvis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpixels_per_cell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mhog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhogvis2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpixels_per_cell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhogvis3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpixels_per_cell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Plot the various HoG results with differing cell sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\michael\\envs\\python3.6env\\lib\\site-packages\\skimage\\feature\\_hog.py\u001b[0m in \u001b[0;36mhog\u001b[1;34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, transform_sqrt, feature_vector, multichannel)\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morientation_histogram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[0mnormalized_blocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m                 \u001b[0m_hog_normalize_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblock_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \"\"\"\n",
      "\u001b[1;32mc:\\users\\michael\\envs\\python3.6env\\lib\\site-packages\\skimage\\feature\\_hog.py\u001b[0m in \u001b[0;36m_hog_normalize_block\u001b[1;34m(block, method, eps)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0meps\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Selected block normalization method is invalid.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Selected block normalization method is invalid."
     ]
    }
   ],
   "source": [
    "hog, hogvis = skimage.feature.hog(image, pixels_per_cell=(32, 32), visualize=True)\n",
    "hog, hogvis2 = skimage.feature.hog(image, pixels_per_cell=(16, 16), visualize=True)\n",
    "hog, hogvis3 = skimage.feature.hog(image, pixels_per_cell=(2, 2), visualize=True)\n",
    "\n",
    "# Plot the various HoG results with differing cell sizes\n",
    "plt.figure()\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(hogvis, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(hogvis2, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(hogvis3, cmap=plt.cm.gray)\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
